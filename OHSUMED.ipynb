{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3313604-1515-43ed-9176-ee11e173fc5d",
   "metadata": {},
   "source": [
    "# ðŸ©º Multi-Label Medical Classification: The OHSUMED Project\n",
    "\n",
    "1. Project Introduction & Problem Definition\n",
    "* Objective: To build a robust classification system capable of indexing medical abstracts into the MeSH (Medical Subject Headings) hierarchy.\n",
    "* The Challenge: Unlike standard classification, this is an Extreme Multi-Label problem involving nearly 3,000 active categories and over 300,000 documents. The project evaluates the trade-offs between statistical keyword importance (TF-IDF), semantic embeddings (BERT/Word2Vec), and sequential modeling (RNNs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43daf783-29f3-4863-8a63-4892d57a5bb5",
   "metadata": {},
   "source": [
    "---\n",
    "2. Data Loading & Initial Exploratory Data Analysis (EDA)\n",
    "* **Strategy**: We load the OHSUMED dataset (1987-1991 cohort).\n",
    "* **Key Insight**: Initial analysis revealed a massive label space of 106,799 unique raw tags. A standard document-to-label distribution check confirmed the multi-label nature, with some documents containing up to 30 clinical tags.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8985c23c-a2c0-45b5-88c9-61a99410c269",
   "metadata": {},
   "source": [
    "---\n",
    "3. Data Integrity & Clinical Label Engineering\n",
    "\n",
    "**The \"Check Tag\" Problem**: Analysis showed that the most frequent labels were \"**Human**,\" \"**Male**,\" and \"**Female**.\" These are metadata \"Check Tags\" that provide zero clinical value for disease classification.\n",
    "\n",
    "**Normalization Strategy:**\n",
    "* Implemented a \"Fingerprinting\" algorithm to standardize punctuation and casing (e.g., matching \"Non-U.S. Gov't\" to \"non u s govt\").\n",
    "* Stripped importance markers (*) and subheadings (/diagnosis).\n",
    "* Removed non-clinical demographic noise to force the model to learn Pathology and Pharmacology.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39398a32-74a2-4107-871d-f2768ad820da",
   "metadata": {},
   "source": [
    "---\n",
    "4. The **Pareto Principle**: Data-Driven Dimensionality Reduction\n",
    "\n",
    "* **The Strategy**: To solve the \"Long Tail\" problem where thousands of labels appear only once, I applied the Pareto Principle (**80/20** Rule).\n",
    "* **The Decision**: By calculating the cumulative frequency of clinical assignments, I identified that 2,891 labels cover 80% of all information in the corpus. This data-driven cutoff ensures maximum dataset coverage while maintaining the statistical support required for model convergence\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df58e09-b2df-4dac-a0db-7018025c055e",
   "metadata": {},
   "source": [
    "---\n",
    "5. Feature Engineering (The Input X)\n",
    "\n",
    "**Preprocessing Pipeline**:\n",
    "To maximize the signal-to-noise ratio, I developed a cleaning function:\n",
    "* **Feature Fusion**: Concatenated Title and Abstract to ensure high-value keywords are captured.\n",
    "* **Numerical Normalization**: Replaced all digits with a [num] token to preserve dosage context without bloating the vocabulary.\n",
    "* **Linguistic Consolidation**: Utilized NLTKâ€™s WordNet Lemmatizer to merge variations like \"Infections\" and \"Infection.\"\n",
    "* **Vocabulary Pareto**: Identified that 6,485 unique words account for 90% of the corpus tokens.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9f9780-2849-4482-a5c7-a3939b2dd87d",
   "metadata": {},
   "source": [
    "---\n",
    "6. Feature Representation & Vectorization Showdown\n",
    "\n",
    "Now, we transform the cleaned medical abstracts into numerical matrices. Because OHSUMED is a domain-specific dataset (Medical), the choice of \"how to represent a word\" is the most critical factor in model performance. We implemented a multi-generational comparison to identify the strongest feature signal.\n",
    "\n",
    "We represent the corpus using five distinct methodologies:\n",
    "* Statistical Baselines (Sparse):\n",
    "    * **Bag-of-Words (BoW)**: Simple frequency counts to establish a \"Baseline 0.\"\n",
    "        * ***TF-IDF (1,2-grams)***: Statistical weighting using single words and bigrams (e.g., \"heart failure\") to capture specific clinical phrases.\n",
    "    * **Static Embeddings (Dense)**:\n",
    "        * ***Word2Vec***: Trained directly on this OHSUMED corpus to capture medical-specific semantic relationships.\n",
    "        * ***GloVe***: Pre-trained on 6 Billion tokens (Wikipedia/Web) to compare general-world knowledge against medical-specific data.\n",
    "    * **Dynamic Transformers (SOTA)**:\n",
    "        * ***BioBERT Embeddings***: 768-dimensional vectors extracted from a model pre-trained on millions of PubMed articles, capturing deep clinical context.\n",
    "\n",
    "**Engineering Decisions**\n",
    "\n",
    "To ensure computational efficiency and statistical validity, the following constraints were applied:\n",
    "* **Vocabulary Pareto Cutoff**: Instead of an arbitrary number, I selected a vocabulary size that covers 90% of all tokens in the corpus, ensuring we ignore rare typos while keeping high-value medical terms.\n",
    "* **Memory Optimization**: Frequency-based features are stored as Compressed Sparse Row (CSR) matrices, while embeddings are handled as dense NumPy arrays to optimize the RAM-to-Signal ratio.\n",
    "* **Normalization Alignment**: All vectorizers share the same \"Fingerprinted\" vocabulary to ensure consistency across models.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960075a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Import our custom source files\n",
    "from src.text_processing import clean_mesh_smart, feature_cleaner\n",
    "from src.visualization import plot_raw_mesh_frequencies, plot_label_shift, plot_pareto_coverage\n",
    "from src.feature_extraction import get_doc_vec, get_glove_vec, get_biobert_embeddings_memory_safe\n",
    "from src.ml_models import run_classical_ml_experiment\n",
    "from src.dl_utils import batch_densify, build_sequence_model, evaluate_dl_model_memory\n",
    "from src.visualization import plot_history\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b29c439-84ce-4f56-b273-a68466db643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "splits = {'train': 'train-00000-of-00001.parquet', 'test': 'test-00000-of-00001.parquet'}\n",
    "train = pd.read_parquet(\"hf://datasets/community-datasets/ohsumed/\" + splits[\"train\"])\n",
    "test = pd.read_parquet(\"hf://datasets/community-datasets/ohsumed/\" + splits[\"test\"])\n",
    "\n",
    "# Visualize raw tags\n",
    "plot_raw_mesh_frequencies(train, top_n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf662ff-f1e0-4faa-bff0-ef41a63aa5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean out generic demographic and meta-tags using our heuristic filter\n",
    "train['clinical_terms_list'] = train['mesh_terms'].apply(clean_mesh_smart)\n",
    "test['clinical_terms_list'] = test['mesh_terms'].apply(clean_mesh_smart)\n",
    "\n",
    "plot_label_shift(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0938fbc2-5f24-4dea-a690-64a80d7b207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten cleaned labels and calculate coverage\n",
    "all_clinical = [label for sublist in train['clinical_terms_list'] for label in sublist]\n",
    "counts_series = pd.Series(Counter(all_clinical)).sort_values(ascending=False)\n",
    "\n",
    "cumulative_perc = counts_series.cumsum() / counts_series.sum()\n",
    "n_labels_at_80 = (cumulative_perc <= 0.80).sum()\n",
    "\n",
    "print(f\"Number of labels required to capture 80% of clinical targets: {n_labels_at_80}\")\n",
    "plot_pareto_coverage(cumulative_perc, n_labels_at_80)\n",
    "\n",
    "# Filter targets to the vital few\n",
    "top_clinical_labels = counts_series.head(n_labels_at_80).index.tolist()\n",
    "train['final_target_labels'] = train['clinical_terms_list'].apply(lambda x: [t for t in x if t in top_clinical_labels])\n",
    "test['final_target_labels'] = test['clinical_terms_list'].apply(lambda x:[t for t in x if t in top_clinical_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cbe1c2-761f-4db7-99a3-9d369332800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter empty targets and binarize\n",
    "train = train[train['final_target_labels'].apply(len) > 0].copy()\n",
    "test = test[test['final_target_labels'].apply(len) > 0].copy()\n",
    "\n",
    "mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "y_train = mlb.fit_transform(train['final_target_labels'])\n",
    "y_test = mlb.transform(test['final_target_labels'])\n",
    "\n",
    "# Text Fusion and Cleaning\n",
    "train['X_raw'] = train['title'].fillna('') + \" \" + train['abstract'].fillna('')\n",
    "test['X_raw'] = test['title'].fillna('') + \" \" + test['abstract'].fillna('')\n",
    "\n",
    "train['X_cleaned'] = train['X_raw'].apply(feature_cleaner)\n",
    "test['X_cleaned'] = test['X_raw'].apply(feature_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db206cf9-734f-4d51-83d9-275a0336edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=25000, ngram_range=(1, 2), min_df=2)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train['X_cleaned'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test['X_cleaned'])\n",
    "\n",
    "# 2. GloVe\n",
    "glove_model = api.load(\"glove-wiki-gigaword-100\")\n",
    "X_train_glove = np.array([get_glove_vec(doc, glove_model, 100) for doc in train['X_cleaned']])\n",
    "X_test_glove = np.array([get_glove_vec(doc, glove_model, 100) for doc in test['X_cleaned']])\n",
    "\n",
    "# 3. BioBERT (Memory Safe)\n",
    "biobert_tokenizer = BertTokenizer.from_pretrained('dmis-lab/biobert-base-cased-v1.1')\n",
    "biobert_model = BertModel.from_pretrained('dmis-lab/biobert-base-cased-v1.1')\n",
    "\n",
    "X_train_bert = get_biobert_embeddings_memory_safe(train['X_cleaned'].tolist(), biobert_model, biobert_tokenizer)\n",
    "X_test_bert = get_biobert_embeddings_memory_safe(test['X_cleaned'].tolist(), biobert_model, biobert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a05e9c4-3e1e-45ac-8227-ddf189dfc30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features for downstream modeling\n",
    "sp.save_npz('features/X_train_tfidf.npz', X_train_tfidf)\n",
    "sp.save_npz('features/y_train_sparse.npz', y_train)\n",
    "\n",
    "np.savez_compressed('features/dense_embeddings.npz', \n",
    "                    glove_train=X_train_glove, glove_test=X_test_glove,\n",
    "                    bert_train=X_train_bert, bert_test=X_test_bert)\n",
    "\n",
    "joblib.dump(mlb, 'models/mlb_object.pkl')\n",
    "print(\"âœ… Data preparation complete. Features and targets saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabb3819",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Loading Classical ML Features...\")\n",
    "X_train_bow = sp.load_npz('features/X_train_bow.npz')\n",
    "X_test_bow = sp.load_npz('features/X_test_bow.npz')\n",
    "X_train_tfidf = sp.load_npz('features/X_train_tfidf.npz')\n",
    "X_test_tfidf = sp.load_npz('features/X_test_tfidf.npz')\n",
    "\n",
    "y_train = sp.load_npz('features/y_train_sparse.npz')\n",
    "y_test = sp.load_npz('features/y_test_sparse.npz')\n",
    "\n",
    "dense_data = np.load('features/dense_embeddings.npz')\n",
    "X_train_w2v, X_test_w2v = dense_data['w2v_train'], dense_data['w2v_test']\n",
    "X_train_glove, X_test_glove = dense_data['glove_train'], dense_data['glove_test']\n",
    "X_train_bert, X_test_bert = dense_data['bert_train'], dense_data['bert_test']\n",
    "\n",
    "feature_sets_train = {\"Bag-of-Words\": X_train_bow, \"TF-IDF\": X_train_tfidf, \"W2V\": X_train_w2v, \"GloVe\": X_train_glove, \"BioBERT\": X_train_bert}\n",
    "feature_sets_test = {\"Bag-of-Words\": X_test_bow, \"TF-IDF\": X_test_tfidf, \"W2V\": X_test_w2v, \"GloVe\": X_test_glove, \"BioBERT\": X_test_bert}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41c1f03-a061-47dd-9936-a4c74c9e856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Classical ML Showdown\n",
    "# Runs our massive iteration block, skipping slow/bad combinations, and saving to CSV incrementally\n",
    "results_df = run_classical_ml_experiment(feature_sets_train, feature_sets_test, y_train, y_test, 'results/ohsumed_ml_results.csv')\n",
    "display(results_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab1975c-fd1d-433b-971e-a3682b441c46",
   "metadata": {},
   "source": [
    "---\n",
    "7. Machine Learning approach\n",
    "\n",
    "**Methodology**: Evaluated four feature sets (BoW, TF-IDF, W2V, GloVe) across four classification families using a Binary Relevance (One-Vs-Rest) strategy.\n",
    "\n",
    "Analysis of Classical Results:\n",
    "* **The Winner**: XGBoost on Bag-of-Words (0.3274 F1-Micro) achieved the highest score, proving that non-linear decision trees effectively capture\n",
    "* **Efficiency Leader**: Linear SVM on TF-IDF (0.2991 F1-Micro) provided near-peak performance while being 8x faster than XGBoost.\n",
    "* **Memory Management**: Sequential processing (n_jobs=1) was implemented to prevent memory duplication during the training of the 2,891 independent label-wise classifiers.\n",
    "\n",
    "> Note: Bert embeddings though they do appear in the code are skipped due to long hours needed for classification.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff2d60e-35a9-4474-bd45-68846a0e35a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning Text Preparation\n",
    "train = pd.read_parquet('data/train_cleaned_dl.parquet')\n",
    "test = pd.read_parquet('data/test_cleaned_dl.parquet')\n",
    "\n",
    "# Tokenization setup\n",
    "VOCAB_SIZE = 6485 \n",
    "doc_lens = train['X_cleaned'].apply(lambda x: len(x.split()))\n",
    "MAX_LEN = int(np.percentile(doc_lens, 90))\n",
    "\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"[UNK]\")\n",
    "tokenizer.fit_on_texts(train['X_cleaned'])\n",
    "\n",
    "X_train_dl = pad_sequences(tokenizer.texts_to_sequences(train['X_cleaned']), maxlen=MAX_LEN, padding='post')\n",
    "X_test_final = pad_sequences(tokenizer.texts_to_sequences(test['X_cleaned']), maxlen=MAX_LEN, padding='post')\n",
    "\n",
    "# Use our memory-safe densifier\n",
    "y_train_dense = batch_densify(sp.load_npz('features/y_train_binarized.npz'))\n",
    "y_test_final = batch_densify(sp.load_npz('features/y_test_binarized.npz'))\n",
    "\n",
    "# Validation Split\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train_dl, y_train_dense, test_size=0.2, random_state=42)\n",
    "print(f\"Deep Learning Data Ready. Train Shape: {X_train_final.shape}, Val Shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e8c4a8-c318-4835-8bc8-7ca9631fb32c",
   "metadata": {},
   "source": [
    "---\n",
    "## 8.ðŸ“‘  Deep Learning Performance & Analysis\n",
    "\n",
    "### 8.1. Objective\n",
    "The goal of this phase was to evaluate sequential Deep Learning architectures against the classical machine learning baselines. We aimed to determine if modeling the temporal order of medical abstracts provided a significant lift in classifying documents into the 2,891 Pareto-optimized MeSH categories.\n",
    "    \n",
    "### 8.2. Experimental Setup\n",
    "All models utilized the following unified architecture parameters:\n",
    "* **Vocabulary Size**: 6,485 words (90% Pareto coverage).\n",
    "* **Sequence Length**: 162 tokens (90th percentile of document length).\n",
    "* **Embedding Dimension**: 128 (Latent semantic space).\n",
    "* **Global Architecture**: Utilized Global Average Pooling to mitigate vanishing gradients and capture context across the entire 162-word sequence.\n",
    "* **Output Layer**: 2,891 neurons with Sigmoid activation (Multi-label requirement).\n",
    "* **Loss Function**: Binary Cross-entropy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe8626a-1d03-46ff-9cbc-ceeee3861b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning Training Loop\n",
    "models_to_train =[\"Simple RNN\", \"Bidirectional RNN\", \"LSTM\", \"Bidirectional LSTM\"]\n",
    "trained_models = {}\n",
    "callbacks =[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
    "\n",
    "for model_name in models_to_train:\n",
    "    print(f\"\\n--- Training {model_name} ---\")\n",
    "    model = build_sequence_model(model_name, VOCAB_SIZE, y_train_final.shape[1])\n",
    "    \n",
    "    history = model.fit(X_train_final, y_train_final, epochs=30, batch_size=64, \n",
    "                        validation_data=(X_val, y_val), callbacks=callbacks, verbose=1)\n",
    "    \n",
    "    plot_history(history, model_name)\n",
    "    model.save(f'models/ohsumed_{model_name.replace(\" \", \"_\").lower()}.keras')\n",
    "    trained_models[model_name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d0d3b8-acbe-40bb-843a-5fd3172892d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Final Memory-Safe Evaluation\n",
    "print(\"Evaluating Deep Learning models on the unseen Test Set...\")\n",
    "dl_results_list =[]\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    # evaluate_dl_model_memory handles the batch-chunking and uint8 conversion behind the scenes!\n",
    "    res = evaluate_dl_model_memory(model, X_test_final, y_test_final, name)\n",
    "    dl_results_list.append(res)\n",
    "\n",
    "# Convert to DataFrame, sort by best F1-Score, and display\n",
    "results_dl_df = pd.DataFrame(dl_results_list).sort_values(by=\"F1 (Micro)\", ascending=False)\n",
    "display(results_dl_df)\n",
    "\n",
    "# Save the deep learning results alongside the classical ML results\n",
    "results_dl_df.to_csv('results/ohsumed_dl_results.csv', index=False)\n",
    "print(\"âœ… Deep Learning evaluation complete. All results saved to disk.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a986f23-e6bf-442b-b09f-1214875df398",
   "metadata": {},
   "source": [
    "---\n",
    "### 8.3. Technical Analysis & Insights\n",
    "1. **The Sparsity Challenge**\n",
    "    * In an extreme multi-label environment (2,891 classes), the dataset is 99.9% sparse. During the initial epochs, more complex models (LSTM/Bi-LSTM) tend toward a \"conservative\" baseline, predicting zero for all labels to minimize the loss function. While the Simple RNN broke this barrier to achieve an F1-Micro of 0.1632 (matching our Logistic Regression baseline), the more complex models reached a plateau at the standard 0.5 decision threshold.\n",
    "\n",
    "2. **Statistical vs. Sequential Learning** \n",
    "* A key finding of this project is the dominance of statistical keyword frequency (XGBoost/TF-IDF) over sequential context (RNN/LSTM) for this specific medical corpus. Because medical terminology is highly specific (\"Leukemia\" is rarely ambiguous), the word-counting approach of XGBoost (0.3274 F1) remains the state-of-the-art for this hardware-constrained environment.\n",
    "\n",
    "### 8.4. Engineering Solutions \n",
    "To handle the scale of 290,000 documents and 2,900 labels, several engineering strategies were implemented:\n",
    "1.  Memory-Safe Batch Prediction: Developed a manual chunking algorithm to process the test set in 10,000-row increments, avoiding a RAM spike that caused standard model.predict() to fail.\n",
    "2. Data Type Optimization: Utilized uint8 encoding for target matrices, reducing the RAM footprint of the labels from 6.2 GB to 810 MB.\n",
    "3. Feature Caching: Implemented a local storage system for BioBERT embeddings and Deep Learning tensors to ensure persistence and reproducibility.\n",
    "\n",
    "### 8.5. Final Conclusion  \n",
    "This project successfully established a robust pipeline for Extreme Multi-label Classification. While Deep Learning offers a higher theoretical AUC (0.82), the Classical XGBoost model on Bag-of-Words provided the most effective practical performance.\n",
    "\n",
    "### 8.6. Future Work\n",
    "Further optimization would involve Threshold Tuning (lowering the 0.5 limit) and the application of Weighted Loss Functions to force the LSTMs to prioritize the rare labels over the \"easy\" zeros.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeec8f13-1341-457c-8e27-b6d07bd0017b",
   "metadata": {},
   "source": [
    "## 9. Project Conclusion\n",
    "    \n",
    "**Technical Milestones**\n",
    "This project established a comprehensive pipeline for Extreme Multi-Label Classification (XMLC) on a massive scale. \n",
    "Over the course of the analysis, we successfully navigated the challenges of:\n",
    "* **High Cardinality**: Managing an output space of 2,891 medical categories.\n",
    "* **Big Data Engineering**: Processing 350,000 documents and optimizing RAM usage through uint8 data types and chunked batch predictions.\n",
    "* **Technological Comparison**: Benchmarking 40 years of NLP evolution, from simple frequency counts to 110-million parameter Transformers.\n",
    "\n",
    "**Key Findings**\n",
    "* Keyword Density is crucial: In this medical corpus, statistical keyword models (XGBoost/SVM on TF-IDF) proved highly effective. Because medical jargon is so specific, simple word-counting often provided a clearer signal than sequential learning.\n",
    "* **\"The \"Winner\"**: XGBoost on Bag-of-Words achieved the top score of 0.3274 F1-Micro.\n",
    "* Sequential Challenges: Sequential models (RNNs/LSTMs) required more training time than classical models to overcome the \"all-zero\" baseline caused by extreme label sparsity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cbd70b-9ad5-4940-b10e-ff2f85d7374f",
   "metadata": {},
   "source": [
    "## 10. Future Work: \n",
    "\n",
    "While the current framework provides a stable baseline for large-scale medical indexing, the following avenues represent the logical progression for improving predictive recall and model depth:\n",
    "    \n",
    "**1.** ***Dynamic Threshold Optimization***\n",
    "The application of a universal 0.5 threshold is inherently conservative for sparse multi-label data. Implementing Per-Label Threshold Optimization would allow the model to adjust for rare diseases, significantly increasing Recall without compromising the Precision of high-frequency categories.\n",
    "    \n",
    "**2.** ***Handling Class Imbalance (Focal Loss)***\n",
    "With 2,891 labels, the \"zeros\" vastly outnumber the \"ones.\" Implementing Focal Loss or Weighted Cross-Entropy would force the model to focus on the difficult rare diseases rather than taking the \"easy win\" by predicting zeros.\n",
    "    \n",
    "**3.** ***Hierarchical Label Aggregation***\n",
    "The MeSH vocabulary is a directed acyclic graph. Leveraging Hierarchical Multi-Label Learning (HMLL) would allow the model to utilize relationship dependencies (e.g., predicting \"Neoplasms\" as a prerequisite for predicting \"Lung Neoplasms\"), structurally reducing the search space for the classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
